{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2H3UTIBFT3t4Tse0+2/2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PravallikaSomisetti/CODSOFT/blob/main/titanic_survival_prediction_codsoft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vlso4w4KwrA",
        "outputId": "d28eb06f-1016-445f-db3c-4cc094ee9e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded successfully.\n",
            "\n",
            "--- Training Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "--- Test Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.1+ KB\n",
            "\n",
            "--- Training Data Head ---\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "--- Missing Values in Training Data ---\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "--- Missing Values in Test Data ---\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n",
            "\n",
            "--- Survival Rate ---\n",
            "Survived\n",
            "0    0.616162\n",
            "1    0.383838\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- Training Data after Feature Engineering ---\n",
            "   PassengerId  Survived  Pclass     Sex   Age     Fare Embarked  FamilySize  \\\n",
            "0            1         0       3    male  22.0   7.2500        S           2   \n",
            "1            2         1       1  female  38.0  71.2833        C           2   \n",
            "2            3         1       3  female  26.0   7.9250        S           1   \n",
            "3            4         1       1  female  35.0  53.1000        S           2   \n",
            "4            5         0       3    male  35.0   8.0500        S           1   \n",
            "\n",
            "   IsAlone Title  FarePerPerson  \n",
            "0        0    Mr        3.62500  \n",
            "1        0   Mrs       35.64165  \n",
            "2        1  Miss        7.92500  \n",
            "3        0   Mrs       26.55000  \n",
            "4        1    Mr        8.05000  \n",
            "\n",
            "Numerical features: ['Pclass', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'FarePerPerson']\n",
            "Categorical features: ['Sex', 'Embarked', 'Title']\n",
            "\n",
            "--- Training Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-2857602622.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['FarePerPerson'].replace([np.inf, -np.inf], 0, inplace=True) # Replace inf with 0\n",
            "/tmp/ipython-input-2-2857602622.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['FarePerPerson'].replace([np.inf, -np.inf], 0, inplace=True) # Replace inf with 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n",
            "\n",
            "Validation Accuracy: 0.8436\n",
            "\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       105\n",
            "           1       0.82      0.80      0.81        74\n",
            "\n",
            "    accuracy                           0.84       179\n",
            "   macro avg       0.84      0.84      0.84       179\n",
            "weighted avg       0.84      0.84      0.84       179\n",
            "\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[92 13]\n",
            " [15 59]]\n",
            "\n",
            "--- Performing Cross-Validation ---\n",
            "Cross-Validation Scores: [0.77653631 0.80898876 0.84831461 0.81460674 0.84269663]\n",
            "Mean CV Accuracy: 0.8182\n",
            "Std CV Accuracy: 0.0258\n",
            "\n",
            "--- Making Predictions on Test Data ---\n",
            "\n",
            "Submission file 'submission.csv' created successfully!\n",
            "First 5 rows of the submission file:\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# Assuming 'train.csv' and 'test.csv' are in the same directory as this script.\n",
        "try:\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    # Store PassengerId for submission later\n",
        "    passenger_ids = test_df['PassengerId']\n",
        "    print(\"Datasets loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Make sure 'train.csv' and 'test.csv' are in the correct directory.\")\n",
        "    print(\"You can download them from the Kaggle Titanic competition page.\")\n",
        "    # Continue execution, but subsequent steps will likely fail without dataframes\n",
        "    print(\"Continuing execution without loading dataframes.\")\n",
        "\n",
        "\n",
        "# --- 2. Exploratory Data Analysis (EDA) ---\n",
        "print(\"\\n--- Training Data Info ---\")\n",
        "train_df.info()\n",
        "print(\"\\n--- Test Data Info ---\")\n",
        "test_df.info()\n",
        "\n",
        "print(\"\\n--- Training Data Head ---\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\n--- Missing Values in Training Data ---\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Missing Values in Test Data ---\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Survival Rate ---\")\n",
        "print(train_df['Survived'].value_counts(normalize=True))\n",
        "\n",
        "# Basic visualizations (uncomment to display)\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.countplot(x='Survived', data=train_df)\n",
        "# plt.title('Survival Count')\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(train_df['Age'].dropna(), bins=30, kde=True)\n",
        "# plt.title('Age Distribution')\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(12, 7))\n",
        "# sns.heatmap(train_df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "# plt.title('Correlation Matrix (Training Data)')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# --- 3. Feature Engineering ---\n",
        "def feature_engineer(df):\n",
        "    # Create 'FamilySize' feature\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "\n",
        "    # Create 'IsAlone' feature\n",
        "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "\n",
        "    # Extract 'Title' from 'Name'\n",
        "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # Group rare titles\n",
        "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        "        'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
        "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
        "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "    # Create 'FarePerPerson'\n",
        "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
        "    # Handle potential division by zero if FamilySize can be 0 (though not in this dataset usually)\n",
        "    df['FarePerPerson'].replace([np.inf, -np.inf], 0, inplace=True) # Replace inf with 0\n",
        "\n",
        "    # Drop original Name, SibSp, Parch, Ticket, Cabin (Cabin too many missing)\n",
        "    df = df.drop(['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)\n",
        "    return df\n",
        "\n",
        "train_df = feature_engineer(train_df)\n",
        "test_df = feature_engineer(test_df)\n",
        "\n",
        "print(\"\\n--- Training Data after Feature Engineering ---\")\n",
        "print(train_df.head())\n",
        "\n",
        "\n",
        "# --- 4. Data Preprocessing ---\n",
        "\n",
        "# Separate target variable from training data\n",
        "X = train_df.drop('Survived', axis=1)\n",
        "y = train_df['Survived']\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Remove 'PassengerId' from numerical features as it's just an identifier\n",
        "if 'PassengerId' in numerical_features:\n",
        "    numerical_features.remove('PassengerId')\n",
        "\n",
        "print(f\"\\nNumerical features: {numerical_features}\")\n",
        "print(f\"Categorical features: {categorical_features}\")\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')), # Impute missing numerical values with mean\n",
        "    ('scaler', StandardScaler())                 # Scale numerical features\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # Impute missing categorical values with most frequent\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))   # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (like PassengerId for test, though it will be dropped later)\n",
        ")\n",
        "\n",
        "# --- 5. Model Training ---\n",
        "\n",
        "# Define the model\n",
        "# You can try other models like LogisticRegression, GradientBoostingClassifier, etc.\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
        "                        # ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
        "                        # ('classifier', GradientBoostingClassifier(random_state=42))])\n",
        "\n",
        "# Split training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\n--- Training Model ---\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_val = model.predict(X_val)\n",
        "print(f\"\\nValidation Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
        "print(\"\\nValidation Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "print(\"\\nValidation Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred_val))\n",
        "\n",
        "# Optional: Cross-validation for a more robust evaluation\n",
        "print(\"\\n--- Performing Cross-Validation ---\")\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Std CV Accuracy: {cv_scores.std():.4f}\")\n",
        "\n",
        "# --- Optional: Hyperparameter Tuning with GridSearchCV ---\n",
        "# This can take a long time to run, uncomment if you want to perform tuning\n",
        "# param_grid = {\n",
        "#     'classifier__n_estimators': [50, 100, 200],\n",
        "#     'classifier__max_depth': [None, 10, 20, 30],\n",
        "#     'classifier__min_samples_split': [2, 5, 10]\n",
        "# }\n",
        "# grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "# print(\"\\n--- Starting GridSearchCV for Hyperparameter Tuning ---\")\n",
        "# grid_search.fit(X, y)\n",
        "# print(f\"\\nBest Parameters found: {grid_search.best_params_}\")\n",
        "# print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
        "# # If using GridSearchCV, update the model with the best estimator\n",
        "# # model = grid_search.best_estimator_\n",
        "# print(\"Hyperparameter tuning complete.\")\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Submission ---\n",
        "\n",
        "# Make predictions on the test set\n",
        "# The test_df also needs to be preprocessed with the same steps\n",
        "print(\"\\n--- Making Predictions on Test Data ---\")\n",
        "test_predictions = model.predict(test_df)\n",
        "\n",
        "# Create submission file in the format expected by Kaggle\n",
        "submission_df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': test_predictions})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission.csv' created successfully!\")\n",
        "print(\"First 5 rows of the submission file:\")\n",
        "print(submission_df.head())"
      ]
    }
  ]
}